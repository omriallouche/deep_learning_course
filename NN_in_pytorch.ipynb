{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will build a neural network using PyTorch, and apply it to the Fashion-MNIST dataset. Our goal in this exercise is not necessarily to obtain the best results on the dataset. We care more about understanding the different parameters, getting a hands-on experience training networks, and monitoring and debugging them. For this reason, I actually recommend that you donâ€™t use a GPU, and run the code on your local machine, for simpler debugging.\n",
    "\n",
    "\n",
    "You can get relevant code snippets from [the PyTorch documentation](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) or other sources online. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We will use the Labeled Faces in the Wild dataset (LFW) of Huang et al. 2007. It contains 13,233 images with 5,749 identities, and is the standard benchmark for automatic face verification.  \n",
    "We will split the dataset to 70% train and 30% test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get to know the dataset. Plot a few examples of images and their labels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the distribution of images per label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the data balanced? What effect is imbalanced data expected to have on your model's results? How can you work with imbalanced data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** It's a good practice when working on Neural Networks to start with a very small dataset and overfit on it. While we don't specifically ask you to do so in the sections below, we recommend that you take this approach, and first write and run your code using easy to use and debug platform, on a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your own CNN classifier\n",
    "In this section, you will develop your own CNN classifier.\n",
    "\n",
    "This is meant as an opportunity to get more experience building your own NN architectures using PyTorch, and our focus is on making sure you rewrite and review the needed code and not on obtaining optimal performance. That being said, within the limits of the time you have, try to come up with a NN architecture and hyperparameters that would achieve nice results on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "TensorBoard provides visualization and tooling for machine learning experimentation:\n",
    "- Tracking and visualizing metrics such as loss and accuracy\n",
    "- Visualizing the model graph (ops and layers)\n",
    "- Viewing histograms of weights, biases, or other tensors as they change over time\n",
    "- Projecting embeddings to a lower dimensional space\n",
    "- Displaying images, text, and audio data\n",
    "- Profiling programs\n",
    "\n",
    "Tensorboard worked originally with Tensorflow but can now be used with PyTorch as well.  \n",
    "You can embed a tensorboard widget in a Jupyter Notebook, although if you're not using Google Colab we recommend that you open tensorboard separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started with Tensorboard, please read the following pages:\n",
    "1. https://itnext.io/how-to-use-tensorboard-5d82f8654496\n",
    "1. https://www.datacamp.com/community/tutorials/tensorboard-tutorial\n",
    "1. https://medium.com/@anthony_sarkis/tensorboard-quick-start-in-5-minutes-e3ec69f673af\n",
    "1. https://www.guru99.com/tensorboard-tutorial.html\n",
    "1. https://www.youtube.com/watch?time_continue=1&v=s-lHP8v9qzY&feature=emb_logo\n",
    "1. https://www.youtube.com/watch?v=pSexXMdruFM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Tensorboard to plot:\n",
    "1. The network loss\n",
    "1. Train and test error\n",
    "1. Average weight in the first layer\n",
    "1. Ratio of update to weight\n",
    "1. Identifying vanishing/exploding gradients, dying neurons\n",
    "1. Percent of dead neurons\n",
    "1. Images with errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "Augmenting the data is a useful trick to increase the size of the training set and reduce the generalization error.  \n",
    "\n",
    "Useful resources: \n",
    "- [Explanation about augmentation](https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/)\n",
    "- The [torchvision transforms documentation](https://pytorch.org/docs/stable/torchvision/transforms.html)\n",
    "- The [albumentations](https://github.com/albumentations-team/albumentations) repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to think which transformation can be useful for data augmentation for our task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply 1 or 2 basic transformations and check how they affect the network's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning using a NN pre-trained on ImageNet\n",
    "In this section, we will use a pretrained network and build a classifier using it to predict the labels of our task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might find these resources useful:\n",
    "- https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "- https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
    "- https://www.analyticsvidhya.com/blog/2019/10/how-to-master-transfer-learning-using-pytorch/\n",
    "- https://heartbeat.fritz.ai/transfer-learning-with-pytorch-cfcb69016c72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a frozen pre-trained network\n",
    "Use a VGG-16 network, including its weights pretrained on ImageNet.  \n",
    "Use the pretrained network to obtain the distributed representation in the final layer (the one before the output softmax layer). Freeze the network weights, and add 2 fully connected layers on top of it to classify the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the weights\n",
    "In this section, we'll unfreeze the pre-trained weights of the network and allow them to change.  \n",
    "Be careful - when fine-tuning a network, there is a risk that our attempt to allow the network to adapt to the new domain will lead to a \"catastrophic forgetting\" of what it had previously learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested Resources\n",
    "1. A good explanation of the different losses - https://gombru.github.io/2019/04/03/ranking_loss/\n",
    "1. A repo with code implementing CNN classifiers, Siamese networks and Triplet loss with different selection regimes for the MNIST and Fashion-MNIST datasets - https://github.com/adambielski/siamese-triplet\n",
    "1. There are several resources online for the VGG-Face network (see https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf), that include pre-trained weights on a face recognition dataset. The weights are here - http://www.robots.ox.ac.uk/~vgg/software/vgg_face/, and PyTorch models are here - http://www.robots.ox.ac.uk/~albanie/pytorch-models.html, and you can also check out https://github.com/prlz77/vgg-face.pytorch and https://github.com/claudio-unipv/vggface-pytorch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
