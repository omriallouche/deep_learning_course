{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrolyrics Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "In this section, you'll build a text classifier, determining the genre of a song based on its lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "# from sklearn import metrics\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\npyarrow or fastparquet is required for parquet support",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4ae333526db8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lyrics.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \"\"\"\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m     \u001b[0mimpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\pandas\\io\\parquet.py\u001b[0m in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         raise ImportError(\"Unable to find a usable engine; \"\n\u001b[0m\u001b[0;32m     30\u001b[0m                           \u001b[1;34m\"tried using: 'pyarrow', 'fastparquet'.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                           \u001b[1;34m\"pyarrow or fastparquet is required for parquet \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\npyarrow or fastparquet is required for parquet support"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('lyrics.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification using Bag-of-Words\n",
    "Build a Naive Bayes classifier based on the bag of Words.  \n",
    "You will need to divide your dataset into a train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is pretty large, and keeping 10% for test still gives us 1,000 songs for each category.  \n",
    "I would even consider a small percentage of test set, if I have reasons to believe more data would greatly improve the classifier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(df.sent, df.genre, test_size=0.1, random_state=0) # We used 10,000 songs from each category - 1,000 songs in the test set seem like a lot. \n",
    "\n",
    "X_train_counts = count_vect.fit_transform([\" \".join(sent) for sent in X_train])\n",
    "X_test_counts = count_vect.transform([\" \".join(sent) for sent in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the count vectorizer is only fitted on the train set. It's very easy to allow a leakage in these cases.  \n",
    "The safest way to avoid them is using pipelines, but here we'll focus on regular flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model = MultinomialNB(alpha = 1)\n",
    "model.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note below that when Y values are the names of the classes as strings, the report includes them and is much easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Pop  Hip-Hop  Rock  Country  Metal\n",
      "Pop      6534       60   150      239    551\n",
      "Hip-Hop   243     7016   198      798    550\n",
      "Rock      181      267  6600      267   1233\n",
      "Country  1834      557   433     4016   2643\n",
      "Metal    1931      432   933      779   6534\n",
      "         Pop  Hip-Hop  Rock  Country  Metal\n",
      "Pop      639        8    19       23     85\n",
      "Hip-Hop   32      781    21       96     64\n",
      "Rock      21       46   685       35    179\n",
      "Country  211       87    57      374    333\n",
      "Metal    286       69   169      119    559\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "print('Performance on the train set:')\n",
    "y_pred = model.predict(X_train_counts)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print( pd.DataFrame(cm, index=genres, columns=genres) )\n",
    "\n",
    "print('\\nPerformance on the test set:')\n",
    "y_pred = model.predict(X_test_counts)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print( pd.DataFrame(cm, index=genres, columns=genres) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the classification report - precision, recall, f1 for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Country       0.54      0.83      0.65       774\n",
      "    Hip-Hop       0.79      0.79      0.79       994\n",
      "      Metal       0.72      0.71      0.71       966\n",
      "        Pop       0.58      0.35      0.44      1062\n",
      "       Rock       0.46      0.47      0.46      1202\n",
      "\n",
      "avg / total       0.61      0.61      0.60      4998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_counts)\n",
    "print( classification_report(y_test, y_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix is sometimes better displayed visually, as a heatmap.  \n",
    "Seaborn provides a simple syntax for displaying a heatmap. We can also add as annotations the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6d0c30e450be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap( confusion_matrix(y_test, y_pred), annot='%2.0d' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we created our dataset, we kept roughly an equal number of songs from each genre. Without this step, there would be much more cases of Rock songs, and the heatmap would be dominated by this row/column, attenuating all other genres.  \n",
    "If this is the case, it is often helpful to display the heatmap normalized by the row or column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "normalized_cm = cm / cm.sum(axis=0)\n",
    "print(normalized_cm)\n",
    "sns.heatmap(normalized_cm , annot='%0.2d' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "normalized_cm = cm / cm.sum(axis=1)\n",
    "print(normalized_cm)\n",
    "sns.heatmap(normalized_cm , annot='%0.2d' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification using Word Vectors\n",
    "#### Average word vectors\n",
    "Do the same, using a classifier that averages the word vectors of words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = np.array([sum(w2v[w] for w in sent if w in w2v) for sent in X_train])\n",
    "X_test_vec = np.array([sum(w2v[w] for w in sent if w in w2v) for sent in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Pop  Hip-Hop  Rock  Country  Metal\n",
      "Pop      4700       64   250      743   1777\n",
      "Hip-Hop   135     6872   293      921    584\n",
      "Rock      170      225  6502      371   1280\n",
      "Country  1174      660   725     4348   2576\n",
      "Metal    1758      269  1818     1877   4887\n",
      "         Pop  Hip-Hop  Rock  Country  Metal\n",
      "Pop      483        7    29       80    175\n",
      "Hip-Hop   16      784    25      104     65\n",
      "Rock      16       28   742       38    142\n",
      "Country  116       74    74      515    283\n",
      "Metal    221       27   230      208    516\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = model.predict(X_train_vec)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print( pd.DataFrame(cm, index=genres, columns=genres) )\n",
    "\n",
    "y_pred = model.predict(X_test_vec)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print( pd.DataFrame(cm, index=genres, columns=genres) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section above raises an interesting question - have we introduced leakage by using word vectors trained on the entire dataset, including that of the test data? What do you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfIdf Weighting\n",
    "Do the same, using a classifier that averages the word vectors of words in the document, weighting each word by its TfIdf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(smooth_idf=True, sublinear_tf=False, norm=None, analyzer='word')\n",
    "X_train_tfidf = tfidf_vect.fit_transform([\" \".join(sent) for sent in X_train])\n",
    "X_test_tfidf = tfidf_vect.transform([\" \".join(sent) for sent in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Weight each word by its tfidf value\n",
    "X_train_vec = np.array([sum(w2v[w] for w in sent if w in w2v) for sent in X_train])\n",
    "X_test_vec = np.array([sum(w2v[w] for w in sent if w in w2v) for sent in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification using ConvNet\n",
    "Do the same, using a ConvNet.  \n",
    "The ConvNet should get as input a 2D matrix where each column is an embedding vector of a single word, and words are in order. Use zero padding so that all matrices have a similar length.  \n",
    "Some songs might be very long. Trim them so you keep a maximum of 128 words (after cleaning stop words and rare words).  \n",
    "Initialize the embedding layer using the word vectors that you've trained before, but allow them to change during training.  \n",
    "\n",
    "Extra: Try training the ConvNet with 2 slight modifications:\n",
    "1. freezing the the weights trained using Word2vec (preventing it from updating)\n",
    "1. random initialization of the embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are encouraged to try this question on your own.  \n",
    "\n",
    "You might prefer to get ideas from the paper \"Convolutional Neural Networks for Sentence Classification\" (Kim 2014, [link](https://arxiv.org/abs/1408.5882)).\n",
    "\n",
    "There are several implementations of the paper code in PyTorch online (see for example [this repo](https://github.com/prakashpandey9/Text-Classification-Pytorch) for a PyTorch implementation of CNN and other architectures for text classification). If you get stuck, they might provide you with a reference for your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
